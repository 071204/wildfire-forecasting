{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting FWI using deepFWI Pre-trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "The Fire Weather Index (FWI) is a meteorologically based index used worldwide to estimate fire danger. It consists of different components that account for the effects of fuel moisture and wind on fire behaviour and spread. The higher the FWI, the more favorable the meteorological conditions to trigger a wildfire. This indicator can help shape long-term tourist strategy and to plan future investments under a changing climate.\n",
    "\n",
    "The [`esowc/wildfire-forecasting`](https://github.com/esowc/wildfire-forecasting) project intends to reproduce the Fire Forecasting capabilities of GEFF using Deep Learning and develop further improvements in accuracy, geography and time scale through inclusion of additional variables or optimisation of model architecture & hyperparameters. \n",
    "\n",
    "In this notebook we demonstrate the use of pre-trained Deep Learning models to perform FWI inference. The Deep Learning Model has been trained on 1 year of data and takes as input the four weather forcings used in the numerical calculation of FWI:\n",
    "```\n",
    "* t2     -    Temperature at 2m (K)\n",
    "* tp     -    Total Precipitation accumulated over the previous 24 hours (mm)\n",
    "* rh     -    Relative Humidity (%)\n",
    "* wspeed -    Windspeed (m/s)\n",
    "```\n",
    "\n",
    "These input weather forcings are supplied for 7 days and the model produces FWI forecast for 21 days. There is 1 day of overlap between the 4 weather forcing variable inputs and the output FWI forecast as indicated below:\n",
    "```\n",
    "                                       ____________\n",
    "Weather Forcings (t-6, t-5, ..., t) -> | deepFWI  |  -> deepFWI-Forecast (t, t+1, t+2, ..., t+20)\n",
    "                                       ------------\n",
    "```\n",
    "\n",
    "Along with FWI inference using deepGEFF pre-trained models, we also benchmark these results against the baseline `FWI-Forecast` which are numerically calculated FWI predictions from weather forecast.\n",
    "\n",
    "To run this notebook, make sure you have the `wildfire-dl` `conda` environment activated. Instructions for setting up the environment are available in the project [`README`](https://github.com/esowc/wildfire-forecasting/blob/master/README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure access to the data\n",
    "The `/data/data-7-21` contains the following data - \n",
    "* `fwi-forcings/`: Weather Forcings for 20xx-xx-xx to 20xx-xx-xx --> 7 days --> 7 files \n",
    "* `fwi-reanalysis/`: ERA Reanalysis of FWI for 20xx-xx-xx to 20xx-xx-xx --> 21 days --> 21 files\n",
    "\n",
    "\n",
    "If you wish to explore these datasets further, have a look at the EDA notebooks in `data/EDA/` in the repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the inference and the benchmark\n",
    "\n",
    "For performing inference and then benchmarking the results, we use the `run(**kwargs)` function from [`src/test.py`](https://github.com/esowc/wildfire-forecasting/blob/master/src/test.py) which takes as argument a dict of configuration parameters and boolean for `benchmark`. You can check out more details about this function in [`test.py#L266`](https://github.com/esowc/wildfire-forecasting/blob/master/src/test.py#L266)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.test import run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Providing the configuration options,\n",
    "\n",
    "```\n",
    "* in_days        -    no of input days of weather forcings\n",
    "* out_days       -    no of output days of fwi prediction\n",
    "* checkpoint_file-    path to pretrained checkpoint file\n",
    "* reanalysis_dir -    path to fwi-reanalysis data\n",
    "* forcings_dir   -    path to fwi-forcings data\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    in_days=7,\n",
    "    out_days=21,\n",
    "    checkpoint_file=\"src/model/checkpoints/unet_tapered-fwi_reanalysis-7-21--10/15-18:37unet_tapered-fwi_reanalysis-7-21--10/15-18:37_ckpt_epoch_29.ckpt\",\n",
    "    reanalysis_dir=\"/home/esowc/data/ext/fwi-reanalysis\",\n",
    "    forcings_dir=\"/home/esowc/data/ext/fwi-forcings\",\n",
    "    forecast_dir = \"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "We demonstrate below the metrics for deepFWI predicted values and benchmark them against the numerical fwi-forecast prediction values. Accuracy, Mean Squared Error (MSE) and Mean Absolute Error (MAE), being the best evaluation metrics for comparing regression models, these are presented for 1 FWI prediction (for 10 days) in a global setting. The metrics are calculated against fwi-reanalysis (considered the ground truth). The grouped bar plots indicate the metrics for deepFWI while the line plots are used for fwi-forecast. The FWI values are binned as per the EFFIS categorisation:\n",
    "\n",
    "```\n",
    "* [0, 5.2]     - Very Low\n",
    "* (5.2, 11.2]  - Low\n",
    "* (11.2, 21.3] - Moderate\n",
    "* (21.3, 38.0] - High\n",
    "* (38.0, 50.0] - Very High\n",
    "* (50.0, Inf)  - Extreme\n",
    "```\n",
    "\n",
    "As seen, the deepFWI predictions are consistent with FWI-Forecast and even offer better accuracy for longer term predictions in certain FWI categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bfefca32904e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbenchmark\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/wildfire-forecasting/src/test.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_days\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             multi_day_plot(\n\u001b[0m\u001b[1;32m    305\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbenchmark\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbenchmark_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             )\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "run(**config, benchmark=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
